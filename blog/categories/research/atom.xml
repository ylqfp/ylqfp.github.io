<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Research | LeoYu的技术博客]]></title>
  <link href="http://ylqfp.github.io/blog/categories/research/atom.xml" rel="self"/>
  <link href="http://ylqfp.github.io/"/>
  <updated>2015-06-14T09:59:22+08:00</updated>
  <id>http://ylqfp.github.io/</id>
  <author>
    <name><![CDATA[LeoYu]]></name>
    <email><![CDATA[ylqfp@qq.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[SimApp: A Framework for Detecting Similar Mobile Applications by Online Kernel Learning]]></title>
    <link href="http://ylqfp.github.io/blog/2015/06/13/simapp/"/>
    <updated>2015-06-13T23:26:23+08:00</updated>
    <id>http://ylqfp.github.io/blog/2015/06/13/simapp</id>
    <content type="html"><![CDATA[<p>Abstract
With the popularity of smart phones and mobile devices, the number of mobile applications (a.k.a. &ldquo;apps&rdquo;) has been growing rapidly. Detecting semantically similar apps from a large pool of apps is a basic and important problem, as it is beneficial for various applications, such as app recommendation, app search, etc. However, there is no systematic and comprehensive work so far that focuses on addressing this problem. In order to fill this gap, in this paper, we explore multi-modal heterogeneous data in app markets (e.g., description text, images, user reviews, etc.), and present &ldquo;SimApp&rdquo; &ndash; a novel framework for detecting similar apps using machine learning. Specifically, it consists of two stages: (i) a variety of kernel functions are constructed to measure app similarity for each modality of data; and (ii) an online kernel learning algorithm is proposed to learn the optimal combination of similarity functions of multiple modalities. We conduct an extensive set of experiments on a real-world dataset crawled from Google Play to evaluate SimApp, from which the encouraging results demonstrate that SimApp is effective and promising.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Word Embedding]]></title>
    <link href="http://ylqfp.github.io/blog/2015/06/13/word-embedding/"/>
    <updated>2015-06-13T23:26:06+08:00</updated>
    <id>http://ylqfp.github.io/blog/2015/06/13/word-embedding</id>
    <content type="html"><![CDATA[<p>Word Embeddings技术是目前NLP领域最火热的新技术，据说今年的NAACL2015中有40多篇和Word2vec相关。
<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>@王威廉：Steve Renals算了一下icassp录取文章题目中包含deep learning的数量，发现有44篇，而naacl则有0篇。有一种说法是，语言（词、句子、篇章等）属于人类认知过程中产生的高层认知抽象实体，而语音和图像属于较为底层的原始输入信号，所以后两者更适合做deep learning来学习特征。
</span><span class='line'>2013年3月4日 14:46</span></code></pre></td></tr></table></div></figure></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第一篇博客]]></title>
    <link href="http://ylqfp.github.io/blog/2015/06/13/first-blog/"/>
    <updated>2015-06-13T08:25:27+08:00</updated>
    <id>http://ylqfp.github.io/blog/2015/06/13/first-blog</id>
    <content type="html"><![CDATA[<h1>这是我的第一篇文章</h1>

<blockquote><p>知世故而不世故，知人性而包容万物。</p></blockquote>

<p>本博客包含以下技术内容：</p>

<h2>大数据&amp;&amp;并行</h2>

<ul>
<li>Hadoop</li>
<li>Spark</li>
<li>Storm

<h2>科研</h2></li>
<li>机器学习</li>
<li>自然语言处理</li>
<li>计算机视觉

<h2>JAVA代码</h2>

<p>``` java
import java.nio.channels.FileChannel;</p></li>
</ul>


<p>public interface CallbackInterface(){
    public void dothings();
    public void exeMethods();
}</p>

<p>public class Server1 {</p>

<pre><code>public static void main(String[] args) {
    // TODO Auto-generated method stub
    System.out.println("hello world!!!");
}
</code></pre>

<p>}</p>

<pre><code>## Python代码
</code></pre>

<p>import numpy as np
import scipy.sparse
import scipy.optimize</p>

<p>def softmax_cost(theta, num_classes, input_size, lambda<em>, data, labels):
    &ldquo;&rdquo;&ldquo;
    :param theta:
    :param num_classes: the number of classes
    :param input_size: the size N of input vector
    :param lambda</em>: weight decay parameter
    :param data: the N x M input matrix, where each column corresponds
                 a single test set
    :param labels: an M x 1 matrix containing the labels for the input data
    &rdquo;&ldquo;&rdquo;
    m = data.shape[1]
    theta = theta.reshape(num_classes, input_size)
    theta_data = theta.dot(data)
    theta_data = theta_data - np.max(theta_data)
    prob_data = np.exp(theta_data) / np.sum(np.exp(theta_data), axis=0)
    indicator = scipy.sparse.csr_matrix((np.ones(m), (labels, np.array(range(m)))))
    indicator = np.array(indicator.todense())
    cost = (-1 / m) * np.sum(indicator * np.log(prob_data)) + (lambda<em> / 2) * np.sum(theta * theta)
    grad = (-1 / m) * (indicator - prob_data).dot(data.transpose()) + lambda</em> * theta
    return cost, grad.flatten()
```</p>

<h2>C/C++ 代码</h2>

<pre><code class="cpp">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;math.h&gt;
#include &lt;pthread.h&gt;

#define MAX_STRING 100
#define EXP_TABLE_SIZE 1000
#define MAX_EXP 6
#define MAX_SENTENCE_LENGTH 1000
#define MAX_CODE_LENGTH 40

const int vocab_hash_size = 30000000;  // Maximum 30 * 0.7 = 21M words in the vocabulary

typedef float real;                    // Precision of float numbers

struct vocab_word {
  long long cn;
  int *point;
  char *word, *code, codelen;
};
void InitUnigramTable() {
  int a, i;
  double train_words_pow = 0;
  double d1, power = 0.75;
  table = (int *)malloc(table_size * sizeof(int));
  for (a = 0; a &lt; vocab_size; a++) 
    train_words_pow += pow(vocab[a].cn, power);
  i = 0;
  d1 = pow(vocab[i].cn, power) / train_words_pow;
  for (a = 0; a &lt; table_size; a++) {
    table[a] = i;
    if (a / (double)table_size &gt; d1) {
      i++;
      d1 += pow(vocab[i].cn, power) / train_words_pow;
    }
    if (i &gt;= vocab_size) i = vocab_size - 1;
  }
}
</code></pre>

<h2>Shell</h2>

<pre><code class="sh">#!/bin/bash
# Program:
#       This program shows "Hello World!" in your screen.
# History:
# 2005/08/23    VBird   First release
PATH=/bin:/sbin:/usr/bin:/usr/sbin:/usr/local/bin:/usr/local/sbin:~/bin
export PATH
echo -e "Hello World! \a \n"
exit 0
</code></pre>

<h2>我的爱好</h2>

<h3>Alizee1</h3>

<p><img src="/images/alizee1.jpg"></p>

<h3>Alizee2</h3>

<p><img src="/images/alizee2.jpg"></p>
]]></content>
  </entry>
  
</feed>
